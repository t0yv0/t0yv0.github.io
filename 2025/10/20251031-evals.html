<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-10-31 Fri 12:41 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="Anton Tayanovskyy" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" href="/css/skeleton.min.css" type="text/css"/>
</head>
<body>
<div id="content" class="content">
<div id="outline-container-orgf36956d" class="outline-2">
<h2 id="orgf36956d">evals are not flaky tests</h2>
<div class="outline-text-2" id="text-orgf36956d">
<p>
<span class="timestamp-wrapper"><span class="timestamp">&lt;2025-10-31 Fri&gt;</span></span>
</p>

<p>
Testing LLM-based software with traditional SDLC approaches is a bad idea. Evals are unlike flaky tests in many
important ways. Scaling laws are brutal. Software engineering instincts stop applying even at modest scales.
</p>
</div>
<div id="outline-container-org7245140" class="outline-3">
<h3 id="org7245140">pass or fail is an estimator</h3>
<div class="outline-text-3" id="text-org7245140">
<p>
If you are testing an agent the key system under test is an LLM and some prompts and tools. The system is
non-deterministic. Not only that, the non-determinism is key and intrinsic to what this is doing.
</p>

<p>
Unlike a traditional deterministic software test, a passing test does not prove that "it gets it right".
</p>

<p>
What is more helpful is thinking about testing as building an estimator for an unknown quantity <code>p</code>. A biased coin toss
comes to mind. Suppose the system gets a pass with a probability <code>p</code>. Running a test N times and averaging results
gives you an estimate <code>p_hat</code> of the true value <code>p</code>.
</p>

<p>
Crucially it is easy to fool oneself and decide that a test is reliable because <code>p_hat</code> is high where true <code>p</code> is low.
</p>
</div>
</div>
<div id="outline-container-orgadc36b3" class="outline-3">
<h3 id="orgadc36b3">reliability scales very poorly with the number of tests</h3>
<div class="outline-text-3" id="text-orgadc36b3">
<p>
Suppose engineers have a test suite and when testing a change they want to have a good time. Specifically let us say
they want to have a 90% chance of not being distracted by random failures unrelated to the change. How reliable should
each test be if we have N independent test? A bit of napkin math:
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">p_fail(p, N) &lt; 0.1
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">1 - (1 - p) ** N &lt; 0.1
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">(1 - p) ** N &gt; 0.9
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">log[ (1-p) ** N ] &gt; log 0.9
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">log[1 - p] &gt; log 0.9 / N
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">1 - p &gt; exp (log 0.9 / N)
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">p &gt; 1 - exp (log 0.9 / N)
</span>
<span style="font-weight: bold;">import</span> math

<span style="font-weight: bold;">def</span> <span style="font-weight: bold;">f</span>(N):
    <span style="font-weight: bold;">return</span> 1 - math.exp(math.log(0.9) / N)

<span style="font-weight: bold;">return</span> [(N, f(N)) <span style="font-weight: bold;">for</span> N <span style="font-weight: bold;">in</span> [16, 32, 64, 128, 256, 512, 1024]]
</pre>
</div>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<tbody>
<tr>
<td class="org-right">16</td>
<td class="org-right">0.006563398416385313</td>
</tr>

<tr>
<td class="org-right">32</td>
<td class="org-right">0.0032871017270746927</td>
</tr>

<tr>
<td class="org-right">64</td>
<td class="org-right">0.0016449037176575754</td>
</tr>

<tr>
<td class="org-right">128</td>
<td class="org-right">0.0008227903508094547</td>
</tr>

<tr>
<td class="org-right">256</td>
<td class="org-right">0.00041147983323130966</td>
</tr>

<tr>
<td class="org-right">512</td>
<td class="org-right">0.00020576108542780247</td>
</tr>

<tr>
<td class="org-right">1024</td>
<td class="org-right">0.00010288583546147478</td>
</tr>
</tbody>
</table>

<p>
This is absolutely brutal - if you want to have 1024 tests each test needs to fail with <code>p</code> less than <code>0.0001</code>.
</p>
</div>
</div>
<div id="outline-container-org8fad365" class="outline-3">
<h3 id="org8fad365">how many trials are needed to establish reliability with confidence</h3>
<div class="outline-text-3" id="text-org8fad365">
<p>
The relevant tools here are the <a href="https://mathworld.wolfram.com/ChebyshevInequality.html">Chebyshev inequality</a>, or perhaps the less conservative <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">Wilson score interval</a>.
</p>

<p>
TLDR form a little AI-assist session targeting 90% confidence levels:
</p>

<div class="org-src-container">
<pre class="src src-shell">
<span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">p_fail(p, N) &lt; 0.1
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">1 - (1 - p) ** N &lt; 0.1
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">(1 - p) ** N &gt; 0.9
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">log[ (1-p) ** N ] &gt; log 0.9
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">log[1 - p] &gt; log 0.9 / N
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">1 - p &gt; exp (log 0.9 / N)
</span><span style="font-weight: bold; font-style: italic;"># </span><span style="font-weight: bold; font-style: italic;">p &gt; 1 - exp (log 0.9 / N)
</span>
import math

def f(N):
    <span style="font-weight: bold;">return</span> 1 - math.exp(math.log(0.9) / N)

<span style="font-weight: bold;">return</span> [(N, f(N)) <span style="font-weight: bold;">for</span> N<span style="font-weight: bold;"> in</span> [16, 32, 64, 128, 256, 512, 1024]]
</pre>
</div>

<p>
This is absolutely brutal - if you want to have 1024 tests each test needs to fail with <code>p</code> less than <code>0.0001</code>.
</p>
</div>
</div>
<div id="outline-container-org3aee35f" class="outline-3">
<h3 id="org3aee35f">how many trials are needed to establish reliability with confidence</h3>
<div class="outline-text-3" id="text-org3aee35f">
<p>
The relevant tools here are the <a href="https://mathworld.wolfram.com/ChebyshevInequality.html">Chebyshev inequality</a>, or perhaps the less conservative <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">Wilson score interval</a>.
</p>

<p>
TLDR form a little AI-assist session targeting 90% confidence levels:
</p>

<div class="org-src-container">
<pre class="src src-shell">According to Chebyshev inequality, if you want p &#8804; 0.0001 and observe 0 failures:
- Need roughly *N &gt; 10,000,000* tests
- This gives you confidence that p &#8804; 0.0001

With Wilson at 90% confidence, you need roughly *30,000 test runs with 0 failures*
to be confident the true failure rate is &#8804; 0.0001.
</pre>
</div>

<p>
These numbers are much higher than 10. If your engineers say "we tested this 10 times and it looks fine", you very well
may be accepting an unreliable test into the codebase.
</p>
</div>
</div>
<div id="outline-container-orgadf8b64" class="outline-3">
<h3 id="orgadf8b64">retries do not do what you think</h3>
<div class="outline-text-3" id="text-orgadf8b64">
<p>
As the test suite grows, the engineers complain about "flaky" tests. Eventually someone comes up with a brilliant idea
of retrying them. Let us work through this for a moment.
</p>

<p>
In enterprise software retrying flaky tests is sometimes quite acceptable. Perhaps you have deterministic tests without
fully faked dependencies, such as tests relying on integrations to third-party SAAS products as is often the case these
days. You are confident that your own software is deterministic. In this situation, retrying a flaky test avoids
spending attention on availability blips in the third-party vendor. NOTE the key take-away here is that non-determinism
is not part of your system under test here.
</p>

<p>
What happens with LLM-based software?
</p>

<p>
On the surface, it is great at making tests increase reliability rapidly. Take a test with a true success probability
of <code>p=0.9</code> and retry it 3 times and you get a test with <code>p=0.999</code>. Magic!
</p>

<div class="org-src-container">
<pre class="src src-python">According to Chebyshev inequality, <span style="font-weight: bold;">if</span> you want p &#8804; 0.0001 <span style="font-weight: bold;">and</span> observe 0 failures:
- Need roughly *N &gt; 10,000,000* tests
- This gives you confidence that p &#8804; 0.0001

With Wilson at 90% confidence, you need roughly *30,000 test runs <span style="font-weight: bold;">with</span> 0 failures* to be confident the true failure rate <span style="font-weight: bold;">is</span> &#8804; 0.0001.
</pre>
</div>

<p>
These numbers are much higher than 10. If your engineers say "we tested this 10 times and it looks fine", you very well
may be accepting an unreliable test into the codebase.
</p>
</div>
</div>
<div id="outline-container-org2e70fec" class="outline-3">
<h3 id="org2e70fec">retries do not do what you think</h3>
<div class="outline-text-3" id="text-org2e70fec">
<p>
As the test suite grows, the engineers complain about "flaky" tests. Eventually someone comes up with a brilliant idea
of retrying them. Let us work through this for a moment.
</p>

<p>
In enterprise software retrying flaky tests is sometimes quite acceptable. Perhaps you have deterministic tests without
fully faked dependencies, such as tests relying on integrations to third-party SAAS products as is often the case these
days. You are confident that your own software is deterministic. In this situation, retrying a flaky test avoids
spending attention on availability blips in the third-party vendor. NOTE the key take-away here is that non-determinism
is not part of your system under test here.
</p>

<p>
What happens with LLM-based software?
</p>

<p>
On the surface, it is great at making tests increase reliability rapidly. Take a test with a true success probability
of <code>p=0.9</code> and retry it 3 times and you get a test with <code>p=0.999</code>. Magic!
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="font-weight: bold;">import</span> math
<span style="font-weight: bold;">return</span> 1 - math.<span style="font-weight: bold;">pow</span>(1 - 0.9, 3)
</pre>
</div>

<pre class="example">
0.999
</pre>


<p>
However, such magic comes at a price. If there is in fact a change to your prompts or system behavior that regresses
the true probability of success from 0.9 to 0.5, the retried test still passes 0.875 of the time. There is a very high
chance that the test will flake up only after the engineers have introduced it to the codebase, and finding which
commit is responsible is going to be non-trivial exercise.
</p>
</div>
</div>
<div id="outline-container-orgd0266a8" class="outline-3">
<h3 id="orgd0266a8">what can practitioners do</h3>
<div class="outline-text-3" id="text-orgd0266a8">
<p>
If you do retry these "flaky" tests and truly want to know what regresses them, perhaps auto-detecting these and automating
bisection and repeated evaluation at high <code>N</code> to establish which commit is at fault could work.
</p>

<p>
If you do not retry these "flaky" tests then any newly introduced tests should pass a high <code>N</code>. Engineers are not going
to have time to do this so automating this suggests itself.
</p>

<p>
I do not know that either is practical though.
</p>

<p>
Uncertainty is a fact of life in these systems and <b>finding out precise answers</b> is just very expensive and sometimes
impractical. Teams need to find balance, and engineers can borrow a trick or two from the data science / MLE
discipline:
</p>

<ul class="org-ul">
<li>avoid scale as long as possible by break down the system into smaller prompts with fewer test each</li>
<li>accept uncertainty when your application or circumstances allow it</li>
<li>use high number of trials and/or examples to scoring pass/fail and summing up benchmark scores to reduce variance</li>
<li>manage lifecycle to test at a cadence you can afford</li>
</ul>


<hr />

<p>
<a href="../../index.html">index</a> :: <a href="../../about.html">about</a>
</p>
</div>
</div>
</div>
</div>
</body>
</html>
